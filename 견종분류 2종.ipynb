{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doberman1  파일 길이 :  1906\n",
      "doberman1  :  C:/gunjong/dog/doberman1\\cat_0_1085.jpg\n",
      "doberman1  :  C:/gunjong/dog/doberman1\\dober_0_3908.jpg\n",
      "doberman1  :  C:/gunjong/dog/doberman1\\dober_0_7405.jpg\n",
      "sichu1  파일 길이 :  2000\n",
      "sichu1  :  C:/gunjong/dog/sichu1\\1 - 1000656188.jpg\n",
      "sichu1  :  C:/gunjong/dog/sichu1\\21 - 523674503.jpg\n",
      "sichu1  :  C:/gunjong/dog/sichu1\\4 - 1222292354.jpg\n",
      "ok 3906\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image                      \n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split #from 모듈이름 import 함수이름을 만들어 작성시작한다.\n",
    "                                                        #파이썬이라 맨윗줄에 함수를 넣어 작성해야됨\n",
    "\n",
    "caltech_dir = \"C:/gunjong/dog\"  #caltect_dir에 자신이 쓸 디렉토리를 입력한다(정확한 주소입력)\n",
    "categories = [\"doberman1\",\"sichu1\"] #\"C:/gunjong/dog\" 해당주소안의 정확한 파일이름 작성\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64  #이미지 크기는 64 x 64 로 만든다\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3  # *3으로 한것은 RGB 채널이 3채널이기 때문\n",
    "                                                                        \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories): #이미지 파일을 RGB값으로 바꾸면서 RESIZE 해주고 그 값을 numpy 파일로 저장해주는 코딩\n",
    "    \n",
    "    \n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 doberman\n",
    "#0 1 0 0 이면 sichu 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./multi_image_data.npy\", xy)  #해당 주소로 저장\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2929, 64, 64, 3)\n",
      "2929\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K  #여기부분은 딱히 설명안해주셔도 됩니다\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)#여기부분은 딱히 설명안해주셔도 됩니다\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('./multi_image_data.npy', allow_pickle=True)#해당 주소 가져온다\n",
    "print(X_train.shape)#이미지 크기 , 이미지 64X64로 만들었는지 확인 , RGB값 3채널인지 확인\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"doberman1\",\"sichu1\"] #CNN 컨볼루션 신경망 모델 만들기\n",
    "nb_classes = len(categories)        #Con2D 로 만들수 있다\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model' # 모델을 패치하고 난 NUMPY값 저장\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,214,466\n",
      "Trainable params: 4,214,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 모델의 구조를 요약해 출력한다. 이때까지 코딩한 CONV2D 나 , 이미지 크기설정 등등 확인가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.6176\n",
      "Epoch 00001: val_loss improved from inf to 0.43648, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 134ms/step - loss: 0.7609 - accuracy: 0.6176 - val_loss: 0.4365 - val_accuracy: 0.8444\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8484\n",
      "Epoch 00002: val_loss improved from 0.43648 to 0.29924, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 130ms/step - loss: 0.3835 - accuracy: 0.8484 - val_loss: 0.2992 - val_accuracy: 0.8833\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.8901\n",
      "Epoch 00003: val_loss improved from 0.29924 to 0.24337, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 131ms/step - loss: 0.2775 - accuracy: 0.8901 - val_loss: 0.2434 - val_accuracy: 0.9150\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9082\n",
      "Epoch 00004: val_loss improved from 0.24337 to 0.18127, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 132ms/step - loss: 0.2206 - accuracy: 0.9082 - val_loss: 0.1813 - val_accuracy: 0.9314\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9358\n",
      "Epoch 00005: val_loss improved from 0.18127 to 0.17872, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 13s 139ms/step - loss: 0.1712 - accuracy: 0.9358 - val_loss: 0.1787 - val_accuracy: 0.9365\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9481\n",
      "Epoch 00006: val_loss improved from 0.17872 to 0.16509, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 134ms/step - loss: 0.1394 - accuracy: 0.9481 - val_loss: 0.1651 - val_accuracy: 0.9396\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9553\n",
      "Epoch 00007: val_loss improved from 0.16509 to 0.15162, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 132ms/step - loss: 0.1245 - accuracy: 0.9553 - val_loss: 0.1516 - val_accuracy: 0.9560\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9720\n",
      "Epoch 00008: val_loss improved from 0.15162 to 0.11842, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 129ms/step - loss: 0.0858 - accuracy: 0.9720 - val_loss: 0.1184 - val_accuracy: 0.9662\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9744\n",
      "Epoch 00009: val_loss did not improve from 0.11842\n",
      "92/92 [==============================] - 10s 107ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.1317 - val_accuracy: 0.9591\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9761\n",
      "Epoch 00010: val_loss improved from 0.11842 to 0.11577, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 133ms/step - loss: 0.0713 - accuracy: 0.9761 - val_loss: 0.1158 - val_accuracy: 0.9632\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9870\n",
      "Epoch 00011: val_loss did not improve from 0.11577\n",
      "92/92 [==============================] - 10s 108ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.1413 - val_accuracy: 0.9580\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9928\n",
      "Epoch 00012: val_loss did not improve from 0.11577\n",
      "92/92 [==============================] - 10s 107ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.1224 - val_accuracy: 0.9642\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9925\n",
      "Epoch 00013: val_loss improved from 0.11577 to 0.10090, saving model to ./model\\multi_img_classification.model\n",
      "INFO:tensorflow:Assets written to: ./model\\multi_img_classification.model\\assets\n",
      "92/92 [==============================] - 12s 131ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.1009 - val_accuracy: 0.9601\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9870\n",
      "Epoch 00014: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 108ms/step - loss: 0.0348 - accuracy: 0.9870 - val_loss: 0.1144 - val_accuracy: 0.9632\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 00015: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 108ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.1176 - val_accuracy: 0.9632\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9969\n",
      "Epoch 00016: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 108ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.1311 - val_accuracy: 0.9683\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9952\n",
      "Epoch 00017: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 109ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.1026 - val_accuracy: 0.9724\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9939\n",
      "Epoch 00018: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 109ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.1157 - val_accuracy: 0.9642\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9942\n",
      "Epoch 00019: val_loss did not improve from 0.10090\n",
      "92/92 [==============================] - 10s 109ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.1287 - val_accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])\n",
    "#해당주소 이미지파일들을 강화학습 시켜 견종을 분류시키기 위한 강화학습코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 23ms/step - loss: 0.1287 - accuracy: 0.9652\n",
      "정확도 : 0.9652\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "# 정확도가 얼마인지 알아봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#해당 강화학습이 얼만큼 안정성을 찾았는지에 대해 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029319C6E8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "해당 doberman (1).jpg이미지는 도베르만로 추정됩니다.\n",
      "해당 doberman (2).jpg이미지는 시츄으로 추정됩니다.\n",
      "해당 doberman (3).jpg이미지는 도베르만로 추정됩니다.\n",
      "해당 doberman (4).jpg이미지는 도베르만로 추정됩니다.\n",
      "해당 doberman (5).jpg이미지는 도베르만로 추정됩니다.\n",
      "해당 sichu (1).jpg이미지는 시츄으로 추정됩니다.\n",
      "해당 sichu (2).jpg이미지는 시츄으로 추정됩니다.\n",
      "해당 sichu (3).jpg이미지는 시츄으로 추정됩니다.\n",
      "해당 sichu (4).jpg이미지는 시츄으로 추정됩니다.\n",
      "해당 sichu (5).jpg이미지는 시츄으로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "caltech_dir = \"C:/gunjong/test/test1/test2\" #견종분류 예시용 디렉토리 파일 주소\n",
    "image_w = 64\n",
    "image_h = 64 #해당 이미지 크기는 위와 동일한 64 X 64 크기로 설정\n",
    "\n",
    "pixels = image_h * image_w * 3 # *3으로 한것은 RGB 채널이 3채널이기 때문\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.jpg\")\n",
    "for i, f in enumerate(files):  #이미지 파일을 RGB값으로 바꾸면서 RESIZE 해주고 그 값을 numpy 파일로 저장해주는 코드\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data) \n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('./model/multi_img_classification.model')# 모델을 패치하고 난 NUMPY값 출력\n",
    "\n",
    "prediction = model.predict(X) # data를 넣어 결과를 예측시킨다. → predict() 메서드 \n",
    "                              # 분류작업을 위해 가장 중요한 메서드 이다.\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "for i in prediction: #강화학습이 끝나고 분류작업을 하기위한 코드 작성\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"도베르만\"\n",
    "    else : pre_ans_str = \"시츄\"\n",
    "        \n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "                            \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
